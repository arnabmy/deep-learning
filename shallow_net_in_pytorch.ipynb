{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shallow_net_in_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabmy/deep-learning/blob/master/shallow_net_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y5PaBROsROW",
        "colab_type": "text"
      },
      "source": [
        "Shallow Neural Network in PyTorch (DEMO) -MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g89sMuOgsat7",
        "colab_type": "text"
      },
      "source": [
        "Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCW5Tk5qsSO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAgDRIdZtwfb",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_RRv51tsWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = MNIST('data', train=False, transform=transforms.ToTensor())\n",
        "# ...toTensor() scales pixels from [0, 255] to [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPjM1GOrt1m5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfe175f5-0e5f-4fed-88ce-ae2d296a3bee"
      },
      "source": [
        "train.data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg52mAEit7KX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23960fb8-faea-4ba1-eb9f-de471aa7eca8"
      },
      "source": [
        "train.data[0] # not scaled! pixel from 0 to 255(black)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
              "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
              "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
              "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
              "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
              "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
              "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
              "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
              "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
              "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
              "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
              "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fgTZlcmt-qM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "d71c6b3d-9f45-4695-ab13-d2f91a70dbc9"
      },
      "source": [
        "plt.imshow(train.data[0].numpy().squeeze(),cmap='gray_r')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fed4d8572b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwWArzGoGmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQO6KxlfvAKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "db9dd562-8f2a-4970-a7bc-2c4c21886ed7"
      },
      "source": [
        "train.targets[0:100]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
              "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
              "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
              "        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
              "        7, 8, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfymhtBGxR2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5891ab6b-106f-4446-a6c9-e25d70ae78bd"
      },
      "source": [
        "train.targets.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szoHKz1fxVZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e52863aa-eeef-4254-9a14-ea97e7c927c9"
      },
      "source": [
        "train.targets.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__PnCodHxcvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fa17a5d-4949-4116-ed52-a9c7438779df"
      },
      "source": [
        "test.targets.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl3JopIKxiUD",
        "colab_type": "text"
      },
      "source": [
        "Batch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVqTzmOMxfSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True) \n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128) \n",
        "# ...DataLoader() can also sample and run multithreaded over a set number of workers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gst5lJxiyq9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_sample,y_sample = iter(train_loader).next() #x-images , y-number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIGn1APDzBQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92decac7-006f-4c09-ed26-d0edc1ab0217"
      },
      "source": [
        "X_sample.shape # 1 color channel "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHPu88k6zEIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b371631-82e7-4df3-980f-d5a8a195bb9d"
      },
      "source": [
        "y_sample.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKMajdHJzHrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "adcd92bd-92aa-467b-c871-b66742ae47e7"
      },
      "source": [
        "y_sample"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 6, 1, 1, 6, 6, 6, 3, 2, 2, 4, 5, 2, 5, 9, 1, 7, 7, 4, 1, 1, 2, 9, 2,\n",
              "        9, 9, 0, 0, 6, 9, 7, 9, 5, 7, 4, 6, 6, 9, 5, 1, 4, 9, 2, 0, 0, 8, 4, 1,\n",
              "        1, 5, 0, 0, 2, 3, 0, 5, 4, 6, 6, 2, 1, 1, 6, 8, 8, 2, 4, 9, 8, 6, 0, 0,\n",
              "        3, 6, 7, 7, 8, 8, 4, 3, 1, 8, 1, 5, 2, 1, 2, 9, 5, 1, 0, 9, 7, 5, 8, 5,\n",
              "        5, 9, 5, 0, 4, 2, 7, 3, 7, 3, 5, 4, 4, 7, 7, 8, 7, 1, 7, 9, 6, 5, 0, 1,\n",
              "        3, 8, 1, 3, 6, 3, 1, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUb6ZJ7bzRo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f06b8dec-68ad-42ad-e7ba-7bfe796ed8fd"
      },
      "source": [
        "X_sample[0] # scaled between 0 to 1 during batch"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.1922, 0.0000,\n",
              "          0.0000, 0.0000, 0.3490, 0.4314, 0.9961, 0.9961, 1.0000, 0.7412,\n",
              "          0.0706, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0314, 0.1843, 0.7529, 0.9373, 0.8863, 0.2353,\n",
              "          0.6039, 0.7843, 0.9686, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.1765, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.1529, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.5020, 0.4196, 0.4196,\n",
              "          0.0745, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5765, 0.9725, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.7373, 0.6275, 0.6275, 0.2275, 0.0275, 0.0039, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216,\n",
              "          0.5020, 0.9843, 0.9922, 0.9922, 0.9922, 0.9725, 0.8392, 0.2902,\n",
              "          0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7843,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.5373, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7843,\n",
              "          0.9922, 0.9922, 0.9922, 0.4784, 0.0549, 0.0157, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255,\n",
              "          0.9412, 0.9922, 0.9922, 0.8471, 0.5216, 0.0353, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.2784, 0.6667, 0.9922, 0.9922, 0.9922, 0.6431, 0.2510, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0314, 0.1804, 0.6902, 0.9765, 0.9922, 0.9490, 0.9059,\n",
              "          0.4863, 0.3059, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.4863, 0.9137, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.5647, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.7569, 0.9922,\n",
              "          0.9922, 0.9922, 0.9922, 0.9294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.1176,\n",
              "          0.5373, 0.7176, 0.9608, 0.9490, 0.1490, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0314, 0.8824, 0.9922, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0431, 0.7176, 0.9922, 0.9922, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235,\n",
              "          0.6784, 0.9922, 0.9922, 0.9922, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
              "          0.6353, 0.4157, 0.0314, 0.3647, 0.4353, 0.4745, 0.6353, 0.9608,\n",
              "          0.9922, 0.9922, 0.9843, 0.9255, 0.1961, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.7176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9725, 0.4863, 0.1294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745,\n",
              "          0.3882, 0.6078, 0.9922, 0.9922, 0.9922, 0.9922, 0.6784, 0.3882,\n",
              "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwK6OcsLzqVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_flat_sample = X_sample.view(X_sample.shape[0], -1) # view() reshapes Tensor (confusingly)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bslM4ojv0kSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cbb873d6-59a8-445f-ff8e-e204a6141cdb"
      },
      "source": [
        "X_flat_sample.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "radi0Oxc1H14",
        "colab_type": "text"
      },
      "source": [
        "Design Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3hzD6X05TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784\n",
        "n_dense = 64\n",
        "n_out = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUZS0z81PsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(n_input,n_dense), #hidden layer\n",
        "    nn.Sigmoid(),#activation function\n",
        "    nn.Linear(n_dense,n_out) #output layer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7EYtEff1pr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "4effc902-57f9-43ee-e729-fb3731939ff3"
      },
      "source": [
        "summary(model,(1,n_input))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 64]          50,240\n",
            "           Sigmoid-2                [-1, 1, 64]               0\n",
            "            Linear-3                [-1, 1, 10]             650\n",
            "================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.19\n",
            "Estimated Total Size (MB): 0.20\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYlQlMSn2G1S",
        "colab_type": "text"
      },
      "source": [
        "Configure training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM6XjPsI1yN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation # how wrong our network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLY4nAVO2VQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.01) # fix incorrectness by tuning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9HTwOZY3oc0",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4LtH7de2dae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_pct(pred_y, true_y):\n",
        "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
        "  correct = (prediction == true_y).sum().item()\n",
        "  return (correct / true_y.shape[0]) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km-9ENKq2_Jq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "437f8f89-f9a6-44ad-d987-9b5189eb4ccb"
      },
      "source": [
        "n_batches = len(train_loader)\n",
        "n_batches "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCpRUu3g3lCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bb6e355-f4b0-4a4f-964e-a91cbf758dfb"
      },
      "source": [
        "n_epochs = 20 \n",
        "\n",
        "print('Training for {} epochs. \\n'.format(n_epochs))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  avg_cost = 0.0\n",
        "  avg_accuracy = 0.0\n",
        "  \n",
        "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
        "    \n",
        "    # forward propagation:\n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_cost += cost / n_batches\n",
        "    \n",
        "    # backprop and optimization via gradient descent: \n",
        "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # calculate accuracy metric:\n",
        "    accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_accuracy += accuracy / n_batches\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Step {}'.format(i + 1))\n",
        "    \n",
        "  print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n",
        "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n",
        "  # TO DO: add test metrics\n",
        "\n",
        "print('Training complete.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 20 epochs. \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 1/20 complete: Cost: 2.243, Accuracy: 31.2% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 2/20 complete: Cost: 2.080, Accuracy: 61.5% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 3/20 complete: Cost: 1.831, Accuracy: 67.6% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 4/20 complete: Cost: 1.537, Accuracy: 71.3% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 5/20 complete: Cost: 1.278, Accuracy: 75.2% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 6/20 complete: Cost: 1.083, Accuracy: 78.3% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 7/20 complete: Cost: 0.941, Accuracy: 80.5% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 8/20 complete: Cost: 0.836, Accuracy: 82.2% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 9/20 complete: Cost: 0.758, Accuracy: 83.4% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 10/20 complete: Cost: 0.697, Accuracy: 84.4% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 11/20 complete: Cost: 0.648, Accuracy: 85.1% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 12/20 complete: Cost: 0.609, Accuracy: 85.7% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 13/20 complete: Cost: 0.577, Accuracy: 86.2% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 14/20 complete: Cost: 0.550, Accuracy: 86.7% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 15/20 complete: Cost: 0.526, Accuracy: 87.1% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 16/20 complete: Cost: 0.506, Accuracy: 87.5% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 17/20 complete: Cost: 0.489, Accuracy: 87.8% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 18/20 complete: Cost: 0.473, Accuracy: 88.0% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 19/20 complete: Cost: 0.460, Accuracy: 88.3% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 20/20 complete: Cost: 0.447, Accuracy: 88.5% \n",
            "\n",
            "Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9AZRUYE4NoD",
        "colab_type": "text"
      },
      "source": [
        "Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiicF-Sy4M5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e283db83-ac13-418b-8972-2c36aa7de3ca"
      },
      "source": [
        "n_test_batches = len(test_loader)\n",
        "n_test_batches"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gtZUJ5t3qz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20edbb08-4ef2-4720-9864-24bab5ce9d22"
      },
      "source": [
        "model.eval() # disables dropout (and batch norm)\n",
        "\n",
        "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
        "  \n",
        "  avg_test_cost = 0.0\n",
        "  avg_test_acc = 0.0\n",
        "  \n",
        "  for X, y in test_loader:\n",
        "    \n",
        "    # make predictions: \n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    \n",
        "    # calculate cost: \n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_test_cost += cost / n_test_batches\n",
        "    \n",
        "    # calculate accuracy:\n",
        "    test_accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_test_acc += test_accuracy / n_test_batches\n",
        "\n",
        "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
        "\n",
        "# model.train() # 'undoes' model.eval()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test cost: 0.424, Test accuracy: 89.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAzsiSiD4Wnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}